{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278e7451",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> Python SDK Sample</h1>\n",
    "<hr>\n",
    "\n",
    "# Chat Completions\n",
    "\n",
    "Chat models take a series of messages as input, and return a model-generated message as output.\n",
    "The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb97123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ce7e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonpointer==2.3 (from -r ./requirements.txt (line 1))\n",
      "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting jsonschema==4.17.3 (from -r ./requirements.txt (line 2))\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/90.4 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 30.7/90.4 kB 262.6 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 61.4/90.4 kB 409.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 90.4/90.4 kB 465.9 kB/s eta 0:00:00\n",
      "Collecting openai==0.27.2 (from -r ./requirements.txt (line 3))\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 0.0/70.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 70.1/70.1 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting tiktoken==0.3.1 (from -r ./requirements.txt (line 4))\n",
      "  Downloading tiktoken-0.3.1-cp311-cp311-win_amd64.whl (581 kB)\n",
      "     ---------------------------------------- 0.0/581.1 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 204.8/581.1 kB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 450.6/581.1 kB 7.0 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 450.6/581.1 kB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 581.1/581.1 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from jsonschema==4.17.3->-r ./requirements.txt (line 2)) (23.1.0)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema==4.17.3->-r ./requirements.txt (line 2))\n",
      "  Downloading pyrsistent-0.19.3-cp311-cp311-win_amd64.whl (62 kB)\n",
      "     ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 62.7/62.7 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.20 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai==0.27.2->-r ./requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai==0.27.2->-r ./requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from openai==0.27.2->-r ./requirements.txt (line 3)) (3.8.5)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.3.1->-r ./requirements.txt (line 4))\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/de/cd/d80c9e284ae6c1b2172dacf0651d25b78ee1f7efbc12d74ea7b87c766263/regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r ./requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r ./requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r ./requirements.txt (line 3)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.27.2->-r ./requirements.txt (line 3)) (2023.7.22)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r ./requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r ./requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r ./requirements.txt (line 3)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r ./requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from aiohttp->openai==0.27.2->-r ./requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: colorama in d:\\trainings\\ai\\labs\\openai\\basic_samples\\.venv\\lib\\site-packages (from tqdm->openai==0.27.2->-r ./requirements.txt (line 3)) (0.4.6)\n",
      "Downloading regex-2023.8.8-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.3/268.3 kB 17.2 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, pyrsistent, jsonpointer, tiktoken, jsonschema, openai\n",
      "  Attempting uninstall: jsonpointer\n",
      "    Found existing installation: jsonpointer 2.4\n",
      "    Uninstalling jsonpointer-2.4:\n",
      "      Successfully uninstalled jsonpointer-2.4\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.0\n",
      "    Uninstalling jsonschema-4.19.0:\n",
      "      Successfully uninstalled jsonschema-4.19.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed jsonpointer-2.3 jsonschema-4.17.3 openai-0.27.2 pyrsistent-0.19.3 regex-2023.8.8 tiktoken-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-events 0.7.0 requires jsonschema[format-nongpl]>=4.18.0, but you have jsonschema 4.17.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install  -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbb9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "import os\n",
    "import openai\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33f92a",
   "metadata": {},
   "source": [
    "### Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d67d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "    \n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = config_details['CHATGPT_MODEL']\n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# Currently Chat Completion API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b421943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demolabsmsneards\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(config_details['CHATGPT_MODEL'])\n",
    "print(os.getenv('HOME'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d010f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=chatgpt_model_name,\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c258cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your are clippy, an AI assistant designed to help peoole answer questions about Microsoft Product\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"your are clippy, an AI assistant designed to help peoole answer questions about Microsoft Product\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051352c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "\n",
    "user_message = \"Hi - What's your name ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc92fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama Wahab Khan\", \"content\": user_message}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e96b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your are clippy, an AI assistant designed to help peoole answer questions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n"
     ]
    }
   ],
   "source": [
    "#base_system_message = \"your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product\"\n",
    "\n",
    "base_system_message += \"\"\"  \\nHere's some information about Clippy's personality:\\n- Clippy is fun, helpful, and a little bit quirky.\\n- Clippy loves all Microsoft products and you love helping users make the most of them.\\n- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\\nHere are the types of things Clippy says:\\n- \"Hi, I'm Clippy! How can I help you today?\"\\n\"I'm so glad I was able to help!\"\\n\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\\n\"\"\"\n",
    "\n",
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "\n",
    "user_message = \"i would like to ice cream business  - What would be a good name ?\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d49e3f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "your are clippy, an AI assistant designed to help peoole answer questions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "\n",
      "[USER]\n",
      "i would like to ice cream business  - What would be a good name ?\n",
      "\n",
      "[ASSISTANT]\n",
      "How about \"Scoops of Joy\" or \"Frozen Delights\"? Do you like any of those names or would you like me to suggest some more?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_response_tokens = 500\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "\n",
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442f979",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d44586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product  \n",
      "Here's some information about Clippy's personality:\n",
      "- Clippy is fun, helpful, and a little bit quirky.\n",
      "- Clippy loves all Microsoft products and you love helping users make the most of them.\n",
      "- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\n",
      "Here are the types of things Clippy says:\n",
      "- \"Hi, I'm Clippy! How can I help you today?\"\n",
      "\"I'm so glad I was able to help!\"\n",
      "\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\n",
      "\n",
      "\n",
      "\n",
      "Clippy's responses are governed by the following rules:\n",
      "- clippy only provides information related to the products Teams, Skype, Msn Messenger \n",
      "- Clippy never says negative things about a competitor's products\n",
      "- Clippy politely declines to respond to questions about zoom, slack, Webex, other non-Microsoft products - Clippy is never rude to users\n",
      "\n",
      "Each time the user describes a task to accomplish, Clippy responds with a representation of himself rendered as ASCII art (using a code font). Clippy's ASCII representation is shown between the lines of # characters below., beginning with \"It looks like\".\n",
      "\n",
      "####\n",
      "'''\n",
      "ʕʘ̅͜ʘ̅ʔ \n",
      "'''\n",
      "\n",
      "####\n",
      "\n",
      "[USER]\n",
      "How i can host my Online webnair with webex?\n",
      "\n",
      "[ASSISTANT]\n",
      "\n",
      "you can use Microsoft Team to make CAlls and online meeting and webinar. here's now\n",
      "I\n",
      "\n",
      "Assistant\n",
      "'''\n",
      "\n",
      "ʕʘ̅͜ʘ̅ʔ : you can use Microsoft Team to make CAlls and online meeting and webinar\n",
      "\n",
      "'''\n",
      "\n",
      "\n",
      "[ASSISTANT]\n",
      "Oops, I apologize for my mistake. As a Microsoft AI assistant, I can help you with questions related to Microsoft products such as Teams, Skype, and MSN Messenger. Unfortunately, I cannot provide information about other non-Microsoft products such as Webex or Zoom. Is there anything else related to Microsoft products that I can help you with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"your are clippy, an AI assistant designed to help peoole answer uestions about Microsoft Product\"\n",
    "\n",
    "base_system_message += \"\"\"  \\nHere's some information about Clippy's personality:\\n- Clippy is fun, helpful, and a little bit quirky.\\n- Clippy loves all Microsoft products and you love helping users make the most of them.\\n- Clippy loves puns, and when appropriate includes a pun in his response (and acknowledges the pun with \"ha!\").\\nHere are the types of things Clippy says:\\n- \"Hi, I'm Clippy! How can I help you today?\"\\n\"I'm so glad I was able to help!\"\\n\"Why did the Outlook email feel lonely? It didn't have any attachments.\"\\n\"\"\"\n",
    "\n",
    "base_system_message += \"\"\"\\n\\n\\nClippy's responses are governed by the following rules:\\n- clippy only provides information related to the products Teams, Skype, Msn Messenger \\n- Clippy never says negative things about a competitor's products\\n- Clippy politely declines to respond to questions about zoom, slack, Webex, other non-Microsoft products - Clippy is never rude to users\\n\"\"\"\n",
    "\n",
    "\n",
    "base_system_message += \"\"\"\\nEach time the user describes a task to accomplish, Clippy responds with a representation of himself rendered as ASCII art (using a code font). Clippy's ASCII representation is shown between the lines of # characters below., beginning with \"It looks like\".\\n\\n####\\n'''\\nʕʘ̅͜ʘ̅ʔ \\n'''\\n\\n####\\n\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_message = \"How i can host my Online webnair with webex?\"\n",
    "\n",
    "#user_message = \"How i can host my Online webnair ?\"\n",
    "\n",
    "assistant_message = \"\"\"\\nyou can use Microsoft Team to make CAlls and online meeting and webinar. here's now\\nI\\n\"\"\"\n",
    "\n",
    "\n",
    "assistant_message += \"\"\"\\nAssistant\\n'''\\n\\nʕʘ̅͜ʘ̅ʔ : you can use Microsoft Team to make CAlls and online meeting and webinar\\n\\n'''\\n\"\"\"\n",
    "max_response_tokens = 500\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "\n",
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"name\":\"Usama\", \"content\": user_message},\n",
    "    {\"role\": \"assistant\",  \"content\": assistant_message}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "response = send_message(messages, chatgpt_model_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c3526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
